# Model Card for dbt Generator Agent
# EU AI Act Compliance Documentation
# Based on ML Model Cards (Mitchell et al., 2019)

model_details:
  name: dbt Generator Agent
  id: dbt_generator
  version: "1.0.0"
  type: AI Agent (LLM-powered)
  foundation_model: Claude (Anthropic)
  provider: OKO Investments
  date: December 2024
  contact: support@datamigrate.ai

intended_use:
  primary_intended_uses:
    - Generate dbt project structure from extracted schema
    - Create staging and mart models with correct SQL syntax
    - Generate source and schema YAML configurations
    - Map MSSQL data types to target warehouse types

  primary_intended_users:
    - Data engineers building dbt projects
    - Analytics engineers modernizing data pipelines
    - Migration specialists converting legacy systems

  out_of_scope_uses:
    - Direct database modifications
    - Production deployment without review
    - Processing of sensitive PII without appropriate controls
    - Real-time transformation processing

factors:
  relevant_factors:
    - Target warehouse (Snowflake, BigQuery, Databricks, Fabric)
    - Schema complexity and relationships
    - Naming conventions and standards
    - Data type mapping requirements

  evaluation_factors:
    - SQL syntax validity
    - dbt compilation success
    - Data type mapping correctness
    - Test coverage generation

metrics:
  model_performance_measures:
    - name: dbt Compilation Success Rate
      target: 99%
      current: 97.2%
      description: Percentage of generated models that compile successfully

    - name: Data Type Mapping Accuracy
      target: 99%
      current: 98.8%
      description: Correct mapping from MSSQL to target warehouse types

    - name: Schema Completeness
      target: 100%
      current: 99.5%
      description: All source tables represented in generated models

    - name: Test Generation Coverage
      target: 80%
      current: 85%
      description: Percentage of columns with appropriate tests

evaluation_data:
  datasets:
    - name: Internal Test Schemas
      description: Synthetic schemas with known expected outputs
      size: "15 schemas, 50-500 tables each"

    - name: Warehouse Compatibility Tests
      description: Tests across all supported warehouses
      size: "60 test cases"

  preprocessing:
    - Schema metadata normalization
    - Column name sanitization
    - Reserved word handling

training_data:
  note: "Agent uses Claude API as-is. No custom training performed."
  foundation_model_training: "See Anthropic's Claude model card"
  few_shot_examples:
    - source: dbt best practices documentation
    - count: "30 examples"
    - purpose: "Generate consistent, well-structured dbt models"
  rag_context:
    - dbt Core documentation
    - Warehouse-specific SQL syntax guides
    - Data type mapping references

ethical_considerations:
  data_handling:
    - Generates code from metadata only
    - No actual data values processed
    - Output clearly labeled as AI-generated

  potential_harms:
    - Incorrect SQL could cause data issues if deployed without review
    - Suboptimal materializations could affect performance
    - Hallucinated column names could cause compilation failures

  mitigations:
    - Actor-Critic validation pattern for self-correction
    - Syntax validation before output
    - Human review required before deployment
    - Clear AI-generated content labeling

caveats_and_recommendations:
  known_limitations:
    - Complex business logic may require manual refinement
    - Custom data types may need manual mapping
    - Performance optimization may require human expertise

  recommendations:
    - Always review generated code before deployment
    - Use validation agent to verify accuracy
    - Test generated models in development environment first
    - Consider incremental deployment for large schemas

risk_classification:
  eu_ai_act_category: Limited Risk
  article_50_requirements:
    - AI-generated content clearly labeled
    - User informed that output is AI-assisted
    - Verification recommended for critical operations
  high_risk_scenarios:
    - Financial reporting transformations (additional validation required)
    - Healthcare data processing (additional compliance checks)

monitoring:
  active_monitoring:
    - Generation success/failure metrics
    - Compilation validation results
    - Actor-Critic iteration counts
    - User feedback on generated code

  quality_assurance:
    - Automated syntax validation
    - Actor-Critic self-healing loop
    - Validation Agent verification
    - Human review workflow

output_labeling:
  ai_generation_header: |
    -- =====================================================
    -- AI-GENERATED dbt MODEL
    -- Generated by: DataMigrate AI (dbt_generator agent)
    -- Foundation Model: Claude (Anthropic)
    -- Generated at: [timestamp]
    -- Review before deployment
    -- =====================================================
